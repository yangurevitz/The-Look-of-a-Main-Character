{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84302803",
   "metadata": {},
   "source": [
    "# Train and Eval\n",
    "\n",
    "The purpose of this Notebook is to train CNN models on our dataset and evaluate their performance on the classification task. The deeper analysis of the patterns present in their results and how they compare to the survey takers will take place in the “Results Analysis” Notebook.\n",
    "\n",
    "The Notebook is divided in two main sections: “Training” and “Evaluation” that can be run independently. Both sections, however, require the “Imports and Setup” section to be run beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62080cd",
   "metadata": {},
   "source": [
    "## Expected File Structure\n",
    "\n",
    "The code expects the data to be in a folder called “Images”, present at the same level as the Notebook. Inside said folder, the images should be divided between three folders “train”, “valid” and “test”, and inside each of those they should be divided between two folders called “Main” and “Supporting”, according to their class.\n",
    "\n",
    "There should also be a folder called “Checkpoints”, again at the same level as the Notebook, where the model will save its checkpoints during the training process, as well as its history JSON file when it finishes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b632aaa",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcea4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import get_file\n",
    "import tensorflow.keras.optimizers\n",
    "#from tensorflow.keras import activations\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# This Notebook was made using tensorflow version 2.1.0,\n",
    "# other versions may work, but there's no guarantee of that.\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f487fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source for these methods: \n",
    "# https://subscription.packtpub.com/book/data/9781838829131/2/ch02lvl1sec14/implementing-resnet-from-scratch\n",
    "\n",
    "# Loads an image and its label in the format to be used by tensorflow\n",
    "# Also applies the preprocessing methods with which we achieved our best results\n",
    "# Receives the image path and the target size, which is, by default, \n",
    "# set as the size of the iamges downloaded from MAL\n",
    "def load_image_and_label(image_path, target_size=(225, 350)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, np.float32)\n",
    "    image = tf.image.resize(image, target_size)\n",
    "    label = tf.strings.split(image_path, os.path.sep)[-2]\n",
    "    label = (label == NARRATIVE_CLASSES)  # One-hot encode.\n",
    "    label = tf.dtypes.cast(label, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "# Loads and prepares the selected dataset to be used by tensorflow\n",
    "# Must be called once for each subset (train, valid, test)\n",
    "# Receives a pattern representing the paths of the images in the subset,\n",
    "# examples found in the following section, and if the data should or not be suffled,\n",
    "# which should only need to be used for the training subset\n",
    "def prepare_dataset(data_pattern, shuffle=False):\n",
    "    dataset = (tf.data.Dataset.list_files(data_pattern).map(load_image_and_label,\n",
    "               num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE))\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "        \n",
    "    return dataset.prefetch(BATCH_SIZE)\n",
    "\n",
    "NARRATIVE_CLASSES = [\"Main\", \"Supporting\"]\n",
    "\n",
    "# Change the batch size according to how much VRAM you have available\n",
    "BATCH_SIZE = 2\n",
    "BUFFER_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c8727",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patterns representing the paths of the images in the train and valid subsets\n",
    "train_pattern = os.path.sep.join(\n",
    "    [\"Images\", 'train', '*', '*.png'])\n",
    "valid_pattern = os.path.sep.join(\n",
    "    [\"Images\", 'valid', '*', '*.png'])\n",
    "\n",
    "# Loading the subsets\n",
    "train_dataset = prepare_dataset(train_pattern, \n",
    "                                shuffle=True)\n",
    "valid_dataset = prepare_dataset(valid_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec58145",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating, compuling and training the model\n",
    "\n",
    "import tensorflow.keras.applications\n",
    "\n",
    "# Size of the iamges downloaded from MAL\n",
    "array_input = Input(shape=(225, 350, 3))\n",
    "\n",
    "# Loading the ResNet model from tensorflow, trained on the iamgenet dataset\n",
    "resModel = tf.keras.applications.ResNet50(include_top=False,\n",
    "                                          weights=\"imagenet\",\n",
    "                                          input_tensor=array_input,\n",
    "                                          input_shape=(225, 350, 3),\n",
    "                                          pooling='avg')\n",
    "\n",
    "# Use this if you only want to train our new layers\n",
    "#for layer in resModel.layers[:143]:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# Adding our classification layers to the end of the model\n",
    "model = Sequential()\n",
    "model.add(resModel)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compiling the model with the combination of parameters we used to achieve \n",
    "# our best results\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(lr=2e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Saving a checkpoint whenever we achieve a new best result during training\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='./Checkpoints/ResNet50 rmsprop.{epoch:02d}-{val_accuracy:.2f}.hdf5',\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True)\n",
    "\n",
    "# Training the model\n",
    "EPOCHS = 100\n",
    "hist = model.fit(train_dataset,\n",
    "          validation_data=valid_dataset,\n",
    "          epochs=EPOCHS,\n",
    "          callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the final state of the model\n",
    "model.save('./Checkpoints/ResNet50 rmsprop '+EPOCHS+'.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01588cd",
   "metadata": {},
   "source": [
    "### Visualising the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3f7862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting accuracy over time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c519074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting loss over time\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the training history as a JSON file\n",
    "\n",
    "import json\n",
    "\n",
    "histDict = hist.history\n",
    "\n",
    "newDict = {}\n",
    "for key in histDict:\n",
    "    newDict[key] = []\n",
    "    for value in histDict[key]:\n",
    "        newDict[key].append(float(value))\n",
    "\n",
    "json.dump(newDict, open('./Checkpoints/ResNet50 rmsprop '+EPOCHS+' Hist.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04fb343",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0274fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading an example checkpoint\n",
    "model = load_model('./Checkpoints/ResNet50 rmsprop.15-0.62.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test subset\n",
    "\n",
    "test_pattern = os.path.sep.join(\n",
    "    [\"Images\", 'test', '*', '*.png'])\n",
    "\n",
    "test_dataset = prepare_dataset(test_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad59ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the evaluation\n",
    "\n",
    "result = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads and predicts a single image\n",
    "# Return both the result of the prediction and the target label\n",
    "def testImage(folder, group, role, name):\n",
    "    image, label = load_image_and_label(os.path.sep.join(\n",
    "                    [folder, group, role, name]))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    result = model.predict(image)\n",
    "    return result, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to use testImage\n",
    "\n",
    "name = \"Hildegard von Mariendorf.png\"\n",
    "result, label = testImage(\"Images\", \"test\", \"Main\", name)\n",
    "print(label)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the predictions for each character in the test subset\n",
    "\n",
    "import pathlib\n",
    "\n",
    "characters = {\"Main\": {}, \"Supporting\": {}}\n",
    "\n",
    "for role in [\"Main\", \"Supporting\"]:\n",
    "    for path in pathlib.Path(\"Images/test/\"+role).iterdir():\n",
    "        name = str(path).split(\"\\\\\")[-1]\n",
    "        result, label = testImage(\"Images\", \"test\", role, name)\n",
    "        characters[role][name] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the results and saving them as a JSON file\n",
    "\n",
    "import json\n",
    "\n",
    "newDict = {\"Main\": {}, \"Supporting\": {}}\n",
    "for role in [\"Main\", \"Supporting\"]:\n",
    "    for character in characters[role]:\n",
    "        newDict[role][character] = []\n",
    "        for value in characters[role][character]:\n",
    "            newDict[role][character].append(float(value))\n",
    "\n",
    "json.dump(newDict, open(\"Model Test Results.json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu4",
   "language": "python",
   "name": "gpu4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
